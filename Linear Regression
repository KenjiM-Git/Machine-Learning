#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Wed Sep 12 09:05:07 2018

@author: terryharris
"""

import numpy as np
import pandas as pd
from mpl_toolkits.mplot3d import Axes3D
from matplotlib import cm
import matplotlib.pyplot as plt

# Edited by Newoko

#Complete the function below
def plotData(x, y):
    
    fig, ax = plt.subplots() # create empty figure 
# ====================== YOUR CODE HERE ======================
# Instructions: Plot the training data into a figure using the 
#               "plt.subplots()" command. Set the axes labels using
#               the ".set_xlabel" and ".set_ylabel" commands. Assume the 
#               population and revenue data have been passed in
#               as the x and y arguments of this function.
#
# Hint: You can use the 'rx' option with plot to have the markers
#       appear as red crosses. Furthermore, you can make the
#       markers larger by using .plot(..., 'rx', MarkerSize=10);

    ax.plot(x,y,'rx',markersize=10)
    ax.set_xlabel("Population of City in 10,000s")
    ax.set_ylabel("Profit in $10,000s")

    return fig



#Complete the function below
def gradientDescent(X, y, theta, alpha, num_iters):
    
    m = len(y) # number of training examples
    J_history = np.zeros(num_iters)

    for i in range(num_iters):
# ====================== YOUR CODE HERE ======================
#         Instructions: Perform a single gradient step on the parameter vector theta. 

#           Hint: While debugging, it can be useful to print out the values of the cost function (computeCost) and gradient here.
    
        theta = theta - alpha * ((1/m) * np.dot(X.transpose(),((np.dot(X,theta)) - y)))
        #theta=np.zeros(2)# replace this with the appropriate values for theta 
        J_history[i] = computeCost(X,y,theta)
    return (theta, J_history)




#Complete the function below
def computeCost(X, y, theta):
#====================== YOUR CODE HERE ======================
#Instructions: Compute the cost of a particular choice of theta
#              You should set J to the cost.
    #J=10000000# replace this with the appropriate values for J
    J=0
    m = len(y)
    J = (1/(2*m))*np.sum(((np.dot(X,theta))-y)**2)
    
   
    return J

print('Plotting Data ...\n')
data = pd.read_csv("ex1data1.txt",names=["X","y"])
x = np.array(data.X)[:,None] # population in 10,0000
y = np.array(data.y) # profit for a food truck
m = len(y) 
fig = plotData(x,y)


input('Program paused. Press enter to continue.\n')
print('Running Gradient Descent ...\n')
ones = np.ones_like(x) #an array of ones of same dimension as x
X = np.hstack((ones,x)) # Add a column of ones to x. hstack means stacking horizontally i.e. columnwise
theta = np.zeros(2) # initialize
iterations = 1500
alpha = 0.01
J=computeCost(X, y, theta)
print("Cost of J() computed as: ", J)
print("\n")

theta, hist = gradientDescent(X, y, theta, alpha, iterations)
print('Theta found by gradient descent: ')
print(theta[0],"\n", theta[1])

# Plot the linear fit
plt.plot(x,y,'rx',x,np.dot(X,theta),'b-')
plt.legend(['Training Data','Linear Regression'])
plt.show()

input('Program paused. Press enter to continue.\n')
# Predict values for population sizes of 35,000 and 70,000
predict1 = np.dot([1, 3.5],theta) # takes inner product to get y_bar
print('For population = 35,000, we predict a profit of ', predict1*10000)

predict2 = np.dot([1, 7],theta)
print('For population = 70,000, we predict a profit of ', predict2*10000)
input('Program paused. Press enter to continue.\n');
print('Visualizing J(theta_0, theta_1) ...\n')

# Grid over which we will calculate J 
theta0_vals = np.linspace(-10, 10, 100)
theta1_vals = np.linspace(-1, 4, 100)
J_vals = np.zeros((len(theta0_vals),len(theta1_vals)))

for i in range(len(theta0_vals)):
    for j in range(len(theta1_vals)):
        t = np.array([theta0_vals[i],theta1_vals[j]])
        J_vals[i][j] = computeCost(X,y,t)

# Surface plot using J_Vals
fig = plt.figure()
ax = plt.subplot(111,projection='3d')
Axes3D.plot_surface(ax,theta0_vals,theta1_vals,J_vals,cmap=cm.coolwarm)
plt.show()

fig = plt.figure()
ax = plt.subplot(111)
plt.contour(theta0_vals,theta1_vals,J_vals) 
plt.show()

print('Loading data ...','\n')
print('Plotting Data ...','\n')
