import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from scipy.optimize import minimize

#Complete the function below
def plotData(X, y):
    pos = X[np.where(y==1)]
    neg = X[np.where(y==0)]
    fig, ax = plt.subplots()
    ax.plot(pos[:,0],pos[:,1],"k+",neg[:,0],neg[:,1],"yo")

    return (fig, ax)


#Complete the function below
def costFunction(theta,X,y):
    m = len(y)
    z = np.dot(X,theta)
    J = 0
    grad = np.zeros(len(theta))
    #print(z)
    h = sigmoid(z)
    #print(h)
    J =  ((1/m) * (np.sum((-y * np.log(sigmoid(np.dot(X,theta)))) - (1-y) * np.log(1-sigmoid(np.dot(X,theta))))))
    #J =(np.sum(-y*np.log(sigmoid(np.dot(X,theta)))-  (1-y)*(np.log(1-sigmoid(np.dot(X,theta)))))/m)
    #print(J)
    #print(h-y)
    
    grad = (np.sum((sigmoid(np.dot(X,theta))-y)[:,None]*X,axis=0)/m)
    #grad = (np.sum((sigmoid(np.dot(X,theta))-y)[:,None]*X,axis=0)/m)
    
    return (J, grad)



#Complete the function below
def sigmoid(z):
    g = np.zeros((z.shape))
    g = np.divide(1.0,(1.0+np.exp(-z)))

    return (g)

#Complete the function below
def predict(theta,X):
   m = len(y)
   z = np.dot(X,theta)
   p = np.zeros((m))
   for i in range (m):
       if sigmoid(z[i]) >= .5:
           p[i] = 1
           #print(sigmoid(np.dot(X,theta))[i])
       else:
           p[i] = 0
   return (p)



	
## Load Data
#  The first two columns contains the exam scores and the third column
#  contains the label.

data = pd.read_csv('ex2data1.txt', names=['x1','x2','y'])
X = np.asarray(data[["x1","x2"]])
y = np.asarray(data["y"])

print("Plotting data with + indicating (y = 1) examples and o indicating",
" (y =0) examples.")
fig, ax = plotData(X, y)
ax.legend(['Admitted', 'Not admitted'])
plt.show()
input('\nProgram paused. Press enter to continue.\n')

# Add intercept term to x and X_test
X = np.hstack((np.ones_like(y)[:,None],X))
initial_theta = np.zeros(3)
cost, grad = costFunction(initial_theta, X, y)

print('Cost at initial theta (zeros): \n', cost)
print('Gradient at initial theta (zeros): \n',grad)

input('\nProgram paused. Press enter to continue.')

res = minimize(costFunction,
	       initial_theta,
	       method='Newton-CG',
	       args=(X,y),
	       jac=True, 
	       options={'maxiter':400,
			'disp':True})

theta = res.x
print('Cost at theta found by minimize: \n', res.fun)
print('theta: \n', theta)


input('\nProgram paused. Press enter to continue.\n')

# In this part, you will use the logistic regression model
#  to predict the probability that a student with score 45 on exam 1 and 
#  score 85 on exam 2 will be admitted.
#  Furthermore, you will compute the training and test set accuracies of 
#  our model.

prob = sigmoid(np.dot([1,45,85],theta))
print('For a student with scores 45 and 85, we predict an ',
      'admission probability of ', prob)

# Compute accuracy on our training set
p = predict(theta, X)

print('Train Accuracy: \n', np.mean(p==y)*100)

input('Program paused. Press enter to continue.\n')
